{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No max depth\n",
      "Accuracy on test set no max depth: 0.99147430\n",
      "10 max depth\n",
      "Accuracy on test set 10 max depth: 0.95121287\n",
      "25 max depth\n",
      "Accuracy on test set 25 max depth: 0.99180946\n",
      "Best max_depth found: 23\n",
      "Accuracy on test set with optimal depth: 0.99193515\n"
     ]
    }
   ],
   "source": [
    "#1.1\n",
    "\n",
    "#Sources:\n",
    "#https://scikit-learn.org/stable/modules/tree.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "#https://www.datacamp.com/tutorial/decision-tree-classification-python\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "traindata = pd.read_csv(\"hw4Train.csv\")\n",
    "testdata = pd.read_csv(\"hw4Test.csv\")\n",
    "#print(testdata.head())\n",
    "#print(traindata.head())\n",
    "\n",
    "X = traindata.iloc[:, :-1]  # Features\n",
    "y = traindata.iloc[:, -1]   # Target\n",
    "\n",
    "Xtest = testdata.iloc[:, :-1]\n",
    "ytest = testdata.iloc[:, -1]\n",
    "\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "maxdepth = 10 \n",
    "predefinedAcc = []\n",
    "\n",
    "\n",
    "#Tree with no max depth\n",
    "print(\"No max depth\")\n",
    "tree0 = DecisionTreeClassifier(random_state=42)\n",
    "tree0.fit(Xtrain, ytrain)\n",
    "testpred0 = tree0.predict(Xtest) \n",
    "accuracytest0 = accuracy_score(ytest, testpred0)\n",
    "print(f'Accuracy on test set no max depth: {accuracytest0:.8f}')\n",
    "#print('Classification Report:')\n",
    "#print(classification_report(ytest, testpred0, zero_division=1))\n",
    "predefinedAcc.append(accuracytest0)\n",
    "\n",
    "print(\"10 max depth\")\n",
    "tree10 = DecisionTreeClassifier(max_depth=10,random_state=42)\n",
    "tree10.fit(Xtrain, ytrain)\n",
    "testpred10 = tree10.predict(Xtest) \n",
    "accuracytest10 = accuracy_score(ytest, testpred10)\n",
    "print(f'Accuracy on test set 10 max depth: {accuracytest10:.8f}')\n",
    "#print('Classification Report:')\n",
    "#print(classification_report(ytest, testpred10, zero_division=1))\n",
    "predefinedAcc.append(accuracytest10)\n",
    "\n",
    "print(\"25 max depth\")\n",
    "tree25 = DecisionTreeClassifier(max_depth=25,random_state=42)\n",
    "tree25.fit(Xtrain, ytrain)\n",
    "testpred25 = tree25.predict(Xtest) \n",
    "accuracytest25 = accuracy_score(ytest, testpred25)\n",
    "print(f'Accuracy on test set 25 max depth: {accuracytest25:.8f}')\n",
    "#print('Classification Report:')\n",
    "#print(classification_report(ytest, testpred25, zero_division=1))\n",
    "predefinedAcc.append(accuracytest25)\n",
    "\n",
    "#Searching for best depth\n",
    "def depthsearch(Xtrain, ytrain, Xval, yval):\n",
    "    best_depth = None\n",
    "    best_accuracy = 0\n",
    "    for depth in range(1, 25):  # Trying depths from 1 to 50\n",
    "        tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "        tree.fit(Xtrain, ytrain)\n",
    "        valpred = tree.predict(Xval)\n",
    "        accuracy = accuracy_score(yval, valpred)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_depth = depth\n",
    "    return best_depth\n",
    "\n",
    "\n",
    "# Find the best max_depth using the validation set\n",
    "best_max_depth = depthsearch(Xtrain, ytrain, Xval, yval)\n",
    "print(f'Best max_depth found: {best_max_depth}')\n",
    "tree2 = DecisionTreeClassifier(max_depth=best_max_depth, random_state=42)\n",
    "tree2.fit(Xtrain, ytrain)\n",
    "testpred = tree2.predict(Xtest)\n",
    "accuracy = accuracy_score(ytest, testpred)\n",
    "print(f'Accuracy on test set with optimal depth: {accuracy:.8f}')\n",
    "#print('Classification Report:')\n",
    "#print(classification_report(ytest, testpred, zero_division=1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1a & 1.2 \n",
    "Accuracy on test set no max depth: 0.99147430\n",
    "\n",
    "Accuracy on test set with optimal depth(23): 0.99193515\n",
    "\n",
    "As we can see from these results, setting depths will influence accuracy, but only very slightly when the depth is in the twenties. Max depth of 10 did however reduce the accuract much more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for attempting to combine multiple optimal features, however using optimal max depth found earlier with optimal feature count resulted in lower accuracy, indicating the the relationship between the hyperparameters is not linear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for best feature count, not used\n",
    "#Source:\n",
    "#https://scikit-learn.org/stable/modules/tree.html\n",
    "def featuresearch(Xtrain, ytrain, Xval, yval):\n",
    "    best_featurecount = None\n",
    "    best_accuracy = 0\n",
    "    for featurecount in range(1, 50):  # Trying features from 1 to 50\n",
    "        tree = DecisionTreeClassifier(max_depth=best_max_depth, random_state=42, max_features=featurecount)\n",
    "        tree.fit(Xtrain, ytrain)\n",
    "        valpred = tree.predict(Xval)\n",
    "        accuracy = accuracy_score(yval, valpred)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_featurecount = featurecount\n",
    "    return best_featurecount\n",
    "\n",
    "\n",
    "#best_featurecount_found = featuresearch(Xtrain, ytrain, Xval, yval)\n",
    "#print(f'Best feature count found: {best_featurecount_found}')\n",
    "#tree4 = DecisionTreeClassifier(max_depth=best_max_depth, random_state=42, max_features=best_featurecount_found)\n",
    "#tree4.fit(Xtrain, ytrain)\n",
    "#testpred = tree4.predict(Xtest)\n",
    "#accuracy = accuracy_score(ytest, testpred)\n",
    "#print(f'Accuracy on test set with optimal featurecount: {accuracy:.4f}')\n",
    "#print('Classification Report:')\n",
    "#print(classification_report(ytest, testpred, zero_division=1))\n",
    "\n",
    "#def leafsearch(Xtrain, ytrain, Xval, yval):\n",
    "#    best_featurecount = None\n",
    "#    best_accuracy = 0\n",
    "#    for featurecount in range(1, 20):  # \n",
    "#        tree = DecisionTreeClassifier(max_depth=best_max_depth, random_state=42, max_features=featurecount)\n",
    "#        tree.fit(Xtrain, ytrain)\n",
    "#        valpred = tree.predict(Xval)\n",
    "#        accuracy = accuracy_score(yval, valpred)\n",
    "#        if accuracy > best_accuracy:\n",
    "#            best_accuracy = accuracy\n",
    "#            best_featurecount = featurecount\n",
    "#    return best_featurecount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "\n",
    "The two parameters that prevents overfitting are max_depth and min_samples_split/min_samples_leaf. \n",
    "\n",
    "Setting a max depth prevents the tree from becoming too complex and specialized on the training set which will lead to low generalization and lessened usefullness in the real world. Configuring min_samples_split or min_samples_leaf ensures that every decision in the tree are informed by multiple samples. Setting a low amount of samples per split will lead to overfitting.\n",
    "\n",
    "In general it is also useful to pre-process the data by reducing features and gaining a better dimensionality on the data.\n",
    "\n",
    "Source:\n",
    "https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "### 1.4\n",
    "\n",
    "SVM may not be optimal for this dataset due to the high number of features that would require kernel tuning. When working with datasets that have a large number of features, one should use models like decision trees that are less sensitive to high dimensionality or to apply robust feature selection and dimensionality reduction techniques before using SVM. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1\n",
    "\n",
    "Feature selection is an imporant step in the building a model for classifying data. It involves selecting a subset of relevant features for use in model construction, based on their importance and relevance to the target variable. Feature selection can achieve the following goals\n",
    "* Improved performance - removing unimportant features can in some cases lead to increase in performance in terms of accuracy and generalization on unseen data.\n",
    "* Reducing overfitting - by removing unimportant features, noise will also be removed, which will reduce overfitting by making the model more focused on the general trends and patterns.\n",
    "* Decreasing training time - Reduced features leads to reduces complexity, which can reduce the time needed for the model to train and test on data.\n",
    "\n",
    "A redundant feature is a feature that in theory contributes to the result, but in practice do not because it is correlating with another more important feature. An irrelevant feature is a feature that has no impact on the the results and shoul√∏d be ignored.\n",
    "\n",
    "\n",
    "### 2.2\n",
    "\n",
    "Using WEKA attribute selection i was able to rank the features on the hw4train.csv dataset. My chosen evaluation methods were Information Gain and chi-square.\n",
    "\n",
    "Information Gain:\n",
    "\n",
    "<img src=\"infogain.png\" alt=\"infogain\" width=\"400\"/>\n",
    "\n",
    "Chi square:\n",
    "\n",
    "<img src=\"chi.png\" alt=\"chi square\" width=\"400\"/>\n",
    "\n",
    "As we can see, these rankings broadly indicate the same features as being more important like IAT and tot size, while features like telnet and ARP having no impact on the results.\n",
    "\n",
    "### 2.3\n",
    "\n",
    "To test the effect feature ranking on J48 decision tree effectiveness i removed all but the top 10 features from infogain rankings and compared the results vs using the full dataset\n",
    "\n",
    "Features included:\n",
    "\n",
    "40  IAT\n",
    "\n",
    "39  Tot size\n",
    "\n",
    "42  Magnitue\n",
    "\n",
    "37  AVG\n",
    "\n",
    "34  Tot sum\n",
    "\n",
    "35  Min\n",
    "\n",
    "2   Header_Length\n",
    "\n",
    "36  Max\n",
    "\n",
    "3   Protocol Type\n",
    "\n",
    "27  TCP\n",
    "\n",
    "#### Results\n",
    "\n",
    "=== Reduced Dataset ===\n",
    "\n",
    "Time taken to build model: 2.96 seconds\n",
    "\n",
    "Time taken to test model on supplied test set: 0.17 seconds\n",
    "    \n",
    "| Result | Number | Accuracy |\n",
    "|---|---|---|\n",
    "| Correctly Classified Instances | 47254 | 98.9861 % |\n",
    "| Incorrectly Classified Instances  | 484  | 1.0139 %  |\n",
    "\n",
    "=== Full Dataset ===\n",
    "\n",
    "Time taken to build model: 11.87 seconds\n",
    "\n",
    "Time taken to test model on supplied test set: 0.68 seconds\n",
    "    \n",
    "| Result | Number | Accuracy |\n",
    "|---|---|---|\n",
    "| Correctly Classified Instances | 47358 | 99.204  % |\n",
    "| Incorrectly Classified Instances  | 380  | 0.796  %  |\n",
    "\n",
    "\n",
    "As seen from the results, reducing the number of features led to a very slight reduction in accuracy from 99.204 to 98.986, while the new accuracy is still very high it will need to be discussed if reduction in accuracy is acceptable when working with security data. The reduced dataset did however significantly reduce the time usage, both for modeling and testing. Even if the original times for testing (0.68 seconds), are quite low, the new time (0.17 seconds), is still 400% faster than the old time, which can be useful in low latency required operations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
